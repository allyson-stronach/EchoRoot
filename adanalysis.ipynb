{
 "metadata": {
  "name": "",
  "signature": "sha256:9063afa613188bbd592f582d016ab8d94f2bcc85657cb6b11c08ad8e6a188136"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
      "from sklearn import cross_validation\n",
      "from sklearn import metrics\n",
      "\n",
      "from model import session"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def retrieve_trafficky_text():\n",
      "    documents = []\n",
      "    labels = []\n",
      "    ads_text_cmd = \"SELECT ads.text AS text FROM ads_attributes JOIN ads ON ads.id = ads_id WHERE ads_attributes.value IN  ('9292103206', '4142395461', '4146870501') \"\n",
      "    e = session.execute(ads_text_cmd)\n",
      "    for text in e:\n",
      "        documents.append(text.text)\n",
      "        labels.append('trafficky')\n",
      "    print 'documents length:', len(documents), 'labels length:', len(labels)\n",
      "    dl_list = [documents, labels]\n",
      "\n",
      "    return dl_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dl_list = retrieve_trafficky_text()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "documents length: 183 labels length: 183\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def retrieve_not_trafficky_text(dl_list):\n",
      "    ads_text_cmd = \"SELECT ads.text AS text FROM ads_attributes JOIN ads ON ads.id = ads_id WHERE ads_attributes.value IN ('3104623985', '2139840845 ', '8183362736', '6032946322', '4088991922')\"\n",
      "    e = session.execute(ads_text_cmd)\n",
      "    for text in e:\n",
      "        dl_list[0].append(text.text)\n",
      "        dl_list[1].append('not trafficky')\n",
      "    print 'documents length:', len(dl_list[0]), 'labels length:', len(dl_list[1])\n",
      "    print 'fraction trafficky:', len([item for item in dl_list[1] if item == 'trafficky'])/240.0\n",
      "\n",
      "    return dl_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dl_list = retrieve_not_trafficky_text(dl_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "documents length: 240 labels length: 240\n",
        "fraction trafficky: 0.7625\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def instantiate_vectorizer():\n",
      "    vectorizer = TfidfVectorizer()\n",
      "\n",
      "    return vectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = instantiate_vectorizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vectorize_ads(dl_list, vectorizer):\n",
      "    X = vectorizer.fit_transform(dl_list[0])\n",
      "    y = np.array(dl_list[1])\n",
      "    print 'X.shape is:', X.shape, 'y.shape is:', y.shape, 'vectorizer:', vectorizer\n",
      "    xy = [X, y]\n",
      "\n",
      "    return xy\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xy = vectorize_ads(dl_list, vectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X.shape is: (240, 843) y.shape is: (240,) vectorizer: TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
        "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
        "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
        "        vocabulary=None)\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def classify_ads(xy):\n",
      "    clf = BernoulliNB()\n",
      "    cv = cross_validation.StratifiedKFold(xy[1],5)\n",
      "    precision=[]\n",
      "    recall=[]\n",
      "    for train, test in cv:\n",
      "        X_train = xy[0][train]\n",
      "        X_test = xy[0][test]\n",
      "        y_train = xy[1][train]\n",
      "        y_test = xy[1][test]\n",
      "        clf.fit(X_train, y_train)\n",
      "        y_hat = clf.predict(X_test)\n",
      "        p,r,_,_ = metrics.precision_recall_fscore_support(y_test, y_hat)\n",
      "        precision.append(p[1])\n",
      "        recall.append(r[1])\n",
      "    print clf\n",
      "    print 'precision:',np.average(precision), '+/-', np.std(precision)\n",
      "    print 'recall:', np.average(recall), '+/-', np.std(recall)\n",
      "    \n",
      "    return clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = classify_ads(xy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
        "precision: 0.983474903475 +/- 0.021784275129\n",
        "recall: 0.978078078078 +/- 0.026852959647\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_sample(vectorizer, clf):\n",
      "    sample = 'Long hair... Long Legs Tall, Busty , Beautiful, Luscious Lips and Curvy Hips<br> All Service<br> In or Out Call<br> Available Days and Nights<br> call 336 307 5841 |'\n",
      "    sample = vectorizer.transform([sample])\n",
      "    c = clf.predict(sample)\n",
      "    \n",
      "    print c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sample(vectorizer, clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['trafficky']\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def describe_features(vectorizer, clf):\n",
      "    probs=clf.feature_log_prob_[1]\n",
      "    features=vectorizer.get_feature_names()\n",
      "    \n",
      "    print 'length of probs:', len(probs), 'length of features:', len(features), 'list of most important features:', sorted(zip(probs,features), reverse=True)[:10]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "describe_features(vectorizer, clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of probs: 843 length of features: 843 list of most important features: [(-0.10610650599454807, u'and'), (-0.21645456316341338, u'with'), (-0.22482281283392958, u'to'), (-0.33111747148355342, u'for'), (-0.34050721183339228, u'the'), (-0.35955540680408671, u'me'), (-0.42923532744207638, u'my'), (-0.45006941434491843, u'experience'), (-0.45006941434491843, u'100'), (-0.46065152367545537, u'love')]\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def main():\n",
      "    pass\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}